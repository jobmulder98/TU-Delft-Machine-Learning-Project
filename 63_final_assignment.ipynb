{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ab9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NUMBER = \"63\"\n",
    "STUDENT_NAME1 = \"Job Mulder\"\n",
    "STUDENT_NUMBER1 = \"4538323\"\n",
    "STUDENT_NAME2 = \"Sam Bekkers\"\n",
    "STUDENT_NUMBER2 = \"4571770\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f97ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert(GROUP_NUMBER != \"\")\n",
    "assert(STUDENT_NAME1 != \"\")\n",
    "assert(STUDENT_NUMBER1 != \"\")\n",
    "assert(STUDENT_NAME2 != \"\")\n",
    "assert(STUDENT_NUMBER2 != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a819d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "We are in the year 2121. The newest sport sensation is solar robot racing. Similar to Formula 1, the races are held on different tracks, however times have changed and those are no longer in different countries but on different planets. The Earth track is well-known for its lush green surroundings, the Mars track for its bright red environment, the Saturn track is instantly recognizable for the brownish soil, and a new race track is currently being built on Neptune, promising a soothing blue background.\n",
    "\n",
    "Like in good old fashioned car racing, no modifications of the car are allowed between races, and in particular the AI cannot be changed. That means we need to develop one single machine learning model that is able to drive on all planets. From past competitions we have data from Earth, Mars, and Saturn (i.e., the 3 datasets provided) but we do not have any data from Neptune yet (i.e., this is a hidden test set), making this season extra challenging. However, we have the possibility to collect more data on 3 planets and can also use test tracks on planets not participating in the competition (i.e., the provided code that allows to collect more data and to change some properties of the environment).\n",
    "\n",
    "As you are just starting out as a solar robot racing AI engineer, you first get the familiarization assignment to train a model solely for Earth before moving on to designing a competition-grade AI.\n",
    "\n",
    "## Robot car AI\n",
    "\n",
    "In this competition, the robot car's actions need to be determined based on only the robot car's last observation (i.e. sensor measurements). More technically: the goal is to create a function $f(observation) \\rightarrow action$, which the robot can continuously apply in a loop on its sensor measurements to determine its next action. This type of function is often called a *policy*.\n",
    "\n",
    "In this assignment, the input and output of the policy function $f$ are defined as:\n",
    "- the input `observation` will be an RGB image (a numpy array) containing a top-down view of the robot's surroundings, including the road ahead.\n",
    "- the output `action` should be an integer out of one of the possible actions (an integer between 0 and 4):\n",
    "    0. Do nothing\n",
    "    1. Accelerate\n",
    "    2. Turn steer left\n",
    "    3. Turn steer right\n",
    "    4. Brake\n",
    "\n",
    "More details will be provided later in the section \"0. Code to get you started\" below.\n",
    "\n",
    "Note that the policy function will completely determine the behavior of the robot.\n",
    "You can think of the robot executing the policy in a never-ending loop (in pseudo-code):\n",
    "```python\n",
    "# Pseudo robot main loop with policy f\n",
    "while True:\n",
    "    observation = read_sensor_measurement()\n",
    "    action = f(observation) # apply the policy\n",
    "    execute_action(action)\n",
    "```\n",
    "In fact, the behavior is already implemented for you in a **simulator**. This means you can test a policy function $f$ by plugging it in the simulator and seeing how your robot car behaves!\n",
    "The simulator also allows us to quantify how well your robot behaved by returning a 'reward' value for each simulation step (a higher reward is better). More details on the rewards will be explained below in Section 0.\n",
    "\n",
    "## Task description: imitation learning\n",
    "\n",
    "These type of tasks, where a robot's policy needs to be optimized to achieve a high expected reward for operating in some environment, is often addressed through *reinforcement learning*. However, in this assigment we will *not* use reinforcement learning techniques, but mainly treat the problem as a **supervised classification task**.\n",
    "The training input (observations) and output (action labels) data will be obtained through demonstrations of humans *manually* controlling the robot car. By training your machine learning models on these demonstrations, you will create an AI which \"imitates\" how a human would drive. This type of supervised machine learning is therefore called *imitation learning*.\n",
    "\n",
    "There are some coding challenges and design choices that you have to solve to use human driving demonstrations as labeled data to create your machine learning models. As before, you will have to think about feature extraction, hyperparemeter optimization, evaluation metrics, comparing models, etc.\n",
    "\n",
    "Once you have trained a classification model, you could define a new policy function which uses your trained model, and test this policy in the simulator. Does your most succesful model also accumulate the most reward in the simulation? Can you make an AI which succesfully drives on known and unknown planets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10e769",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "The deadline is **Sunday October 24th, 2021 at 23:59**. Late submission is –1 grade point per day.\n",
    "\n",
    "* The main deliverable is this Jupyter Notebook, integrating the report (markdown cells) and the code.\n",
    "* Submission is again in the form of a single ZIP file that *includes your notebook, and all files required to run the notebook and reproduce the results*. This includes all used data/demonstrations (including the ones that were provided), any loadable parameter files, any auxiliary scripts, etc.\n",
    "* Name the ZIP file \"**GroupNumber_final_assignment.zip**\", e.g., if you are in group 456, the name would be \"456_final_assignment.zip\".\n",
    "* Unlike previous lab assignments, there are no autograded cells or asserts, but we will grade the notebook manually. Therefore, you are free to add cells as you see fit, as long as the required sections are still present in the notebook.\n",
    "* Make sure that the notebook runs correctly. That is, clear all outputs, restart the kernel and run the notebook from top to bottom. \n",
    "* The notebook needs to be able to run within 20 minutes on a high-end PC, performing all steps (also including training, the only exception is hyperparameter optimization which can be commented out).\n",
    "* In contrast to the practica, please submit the notebook *including* the output (i.e., do not clear the outputs before zipping it up). \n",
    "\n",
    "\n",
    "## Grading Criteria\n",
    "Below you will find an outline of the sections that the notebook needs to contain and what we expect for each part. More specific requirements are listed there as well. The indicated number of points, out of a total of 100, should give you a rough indication of how much effort to put into each part.\n",
    "\n",
    "In general, we will not focus as much on the performance of the method you design, but rather the _level of understanding and argumentation about your design choices_. So, we are not only interested in WHAT you did, but will put a strong emphasis on your reasoning about the WHY. Try to synthesize rather than describing what you did step by step.\n",
    "\n",
    "### Quality of the report (20 points)\n",
    "- Structure & Readability\n",
    " - Logical flow\n",
    " - Connection between parts\n",
    "- Academic English\n",
    " - Do not use short forms, like \"isn't\", \"wouldn't\".\n",
    " - Do not use colloquial style, like \"a couple of\".\n",
    " - Spell check and proofread your report.\n",
    "- Level of detail\n",
    " - Strive for elegant, concise text - longer reports do not necessarily yield higher grades.\n",
    " - There is no need to re-explain theory. Assume that the target audience of the report has followed the course.\n",
    "- Figures & Tables\n",
    " - Choose figures/plots/tables carefully. Only include those that add to the story of the report. Do not put the burden on the reviewer to figure out which results you basing your conclusions on, but specifically refer (parts of) the specific table/plot/figure when needed.\n",
    " - When comparing two or more signals display them in one plot. Explain the colors / line types. The scale of the plots must be carefully chosen in order to clearly convey the information intended. Label the axes in graphs properly (variables and units).\n",
    "- Citations\n",
    " - If you use images, theory and methods beyond what was covered in the course, etc., always reference sources.\n",
    "\n",
    "\n",
    "### Your implementations and answers (80 points)\n",
    "\n",
    "The remainder of this notebook follows the following structure:\n",
    "\n",
    "0. Code to get you starte (0 points, *nothing for you to do here*)\n",
    "1. Explore & Inspect the Data (5 points)\n",
    "2. Prepare the Data and Evaluate Features (15 points)\n",
    "3. Single Planet Action Classification  (35 points)\n",
    "4. Enabling Generalization (20 points)\n",
    "\n",
    "Apart from section 0, you will have to implement and answer questions for all of the other 4 sections to earn points. *For each of these 4 sections, we have various questions or implementation tasks that your submission should address. These are listed in the cells at the end of this notebook.*\n",
    "\n",
    "Note that there is not one best answer to these questions, and the task could be addressed in different ways. We want to know *your* motivation for *your* selected approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf01613",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 0. Code to get you started\n",
    "\n",
    "Note, you will not have to implement anything in this section, but you are free to play around with what is provided here, or copy parts to new cells in your solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192dd7ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing cv2: Kan opgegeven module niet vinden.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;66;03m# you are allowed to use functions from cv2\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# import the simualtion environment\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# wildcard import above does not import \"private\" variables like __version__\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# this makes them available\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing cv2: Kan opgegeven module niet vinden."
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import cv2 # you are allowed to use functions from cv2\n",
    "import glob\n",
    "\n",
    "# import the simualtion environment\n",
    "import car_racing_ro47002 as cr\n",
    "\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1127d2d",
   "metadata": {},
   "source": [
    "First, we explore the available planets. The code below generates an image from the 3 planets. You do not need to understand how this code works, but it should help you understand the context of what we are doing.\n",
    "Note that the images also include your robot car, and the road ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a595ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05183b1236e74bf388af2a6c0edcce94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='planet_id', max=2), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Show screenshot of a sampled environment\n",
    "def plot_planet_example(planet_id):\n",
    "    planet = cr.PLANETS[planet_id]\n",
    "    env = cr.CarRacing(planet)\n",
    "    env.seed(10)\n",
    "    env.reset()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(f'Planet {planet_id}')\n",
    "    env.close()\n",
    "\n",
    "ipywidgets.interactive(plot_planet_example, planet_id=(0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed13a94",
   "metadata": {},
   "source": [
    "## Loading pre-recorded human demonstrations\n",
    "\n",
    "You are provided several pre-recorded demonstrations of a human *manually controlling* the robot car on several tracks on several planets.\n",
    "**You can use this data to train a classifier that you can use to implement one or more better policies, which should (ideally) perform similar to how a human would control the robot car.**\n",
    "\n",
    "Each provided demonstration ...\n",
    "* ... contains a sequence of 1000 (observation, action) pairs ...\n",
    "* ... recorded at a specic planet and track, ...\n",
    "* ... for convenience, also contains (1000 dimensional) arrays containing the fixed planet's and track's id of these input/output pair.\n",
    "\n",
    "A demonstration is stored as a python pickle file.\n",
    "The code below shows how to load the saved demonstrations, and to do some simple pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11bb94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 demonstrations\n",
      "Loaded 1000 samples from demonstrations\\demo-0-0-20211012_155840.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-1-20211012_160607.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-2-20211012_161107.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-3-20211012_161203.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-4-20211012_161237.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-5-20211012_161457.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-6-20211012_161843.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-7-20211012_161923.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-8-20211012_162117.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-0-9-20211012_162157.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-1-10-20211012_170226.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-1-11-20211012_171117.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-2-12-20211012_171400.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demo-2-13-20211012_171617.pickle ...\n",
      "Loaded 1000 samples from demonstrations\\demostud-0-0-20211016_131128.pickle ...\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Look for all the demonstration pickle files in the demonstrations/ directory.\n",
    "#  The originally provided demo files are called: demo-[planet_id]-[track_id]-[datetime].pickle\n",
    "#  Any demo files you record yourself are called: demostud-[planet_id]-[track_id]-[datetime].pickle\n",
    "\n",
    "# CHANGE THIS IF NEEDED: select the pickle file pattern to match ...\n",
    "\n",
    "# DEMO_FILEPATTERN = 'demo-*-*.pickle'      # only use ORIGINALLY provided demo files\n",
    "# DEMO_FILEPATTERN = 'demostud-*-*.pickle'  # only use YOUR own collected demo files\n",
    "DEMO_FILEPATTERN = 'demo*-*.pickle'       # use ALL available demo files\n",
    "\n",
    "# find the relevant filenames\n",
    "filenames = glob.glob(f'demonstrations/{DEMO_FILEPATTERN}')\n",
    "filenames.sort() # ensure the order is well-defined\n",
    "print(f'Found {len(filenames)} demonstrations')\n",
    "\n",
    "# in a loop, load the found pickle files\n",
    "demonstrations = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'rb') as fd:\n",
    "        demonstration = pickle.load(fd)\n",
    "        \n",
    "        actions = demonstration['actions']\n",
    "        print(f'Loaded {actions.shape[0]} samples from {filename} ...')\n",
    "        \n",
    "        demonstrations.append(demonstration)\n",
    "        \n",
    "print(np.unique(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388fd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can combine all the observations, actions, planet and track ids\n",
    "observations = np.concatenate([d['observations'] for d in demonstrations])\n",
    "actions = np.concatenate([d['actions'] for d in demonstrations])\n",
    "planet_ids = np.concatenate([d['planets'] for d in demonstrations])\n",
    "track_ids = np.concatenate([d['tracks'] for d in demonstrations])\n",
    "\n",
    "# pre-processing: subsample and only keep every n-th sample for efficiency\n",
    "# this can speed up training\n",
    "\n",
    "#Extracting data from Earth\n",
    "earth_observations = observations[:10000]\n",
    "earth_actions = actions[:10000]\n",
    "\n",
    "# plt.imshow(observations[60])\n",
    "# ss = 10\n",
    "# observations = observations[::ss]\n",
    "# actions = actions[::ss]\n",
    "# planet_ids = planet_ids[::ss]\n",
    "# track_ids = track_ids[::ss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c823a",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "\n",
    "We here take a closer look at format of the demonstration data. The observations (input) are RGB images. The actions (target class labels) are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656bccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data consists of 15000 (observation, action) pairs:\n",
      "- observations : a (15000, 96, 96, 3) numpy int8 array, i-th entry contains RGB image of sample i\n",
      "- actions      : a (15000,) numpy int array, i-th entry contains action (class) label of sample i\n",
      "- planet_ids   : a (15000,) numpy int array, i-th entry contains the planet_id of sample i\n",
      "- track_ids    : a (15000,) numpy int array, i-th entry contains the track_id of sample i\n"
     ]
    }
   ],
   "source": [
    "# count the total number of observations\n",
    "N = observations.shape[0]\n",
    "\n",
    "print(f'The data consists of {N} (observation, action) pairs:')\n",
    "print(f'- observations : a {observations.shape} numpy int8 array, i-th entry contains RGB image of sample i')\n",
    "print(f'- actions      : a {actions.shape} numpy int array, i-th entry contains action (class) label of sample i')\n",
    "print(f'- planet_ids   : a {planet_ids.shape} numpy int array, i-th entry contains the planet_id of sample i')\n",
    "print(f'- track_ids    : a {track_ids.shape} numpy int array, i-th entry contains the track_id of sample i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121026e",
   "metadata": {},
   "source": [
    "We can inspect inspect a single sample in the recorded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a2b2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action of sample 1:                     1\n",
      "Planet id where sample 1 was recorded:  0\n",
      "Track id where sample 1 was recorded:   0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "# sample index, should be in range [0, N-1]\n",
    "\n",
    "print(f'Action of sample {idx}:                    ', actions[idx])\n",
    "print(f'Planet id where sample {idx} was recorded: ', planet_ids[idx])\n",
    "print(f'Track id where sample {idx} was recorded:  ', track_ids[idx])\n",
    "\n",
    "plt.imshow(observations[idx])\n",
    "plt.title(f'Observation of sample {idx}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff18b10",
   "metadata": {},
   "source": [
    "Note that the observation is just a low-resolution image of the simulated environment.\n",
    "\n",
    "An action (label) is simply an integer. The five possible action values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3021679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_NOOP = 0  # NO-OPeration, i.e. do not steer, accelerate or brake\n",
    "ACTION_ACCEL = 1 # Accelerate\n",
    "ACTION_LEFT = 2  # Steer left\n",
    "ACTION_RIGHT = 3 # Steer right\n",
    "ACTION_BRAKE = 4 # Brake, deaccelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82908e5a",
   "metadata": {},
   "source": [
    "You can use the demonstration data to train and validate your machine learning methods.\n",
    "Of course, you would first need to define some feature extraction procedure(s) to convert the observations into some suitable feature vectors for your machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb2415",
   "metadata": {},
   "source": [
    "## Testing your model in  the simulator\n",
    "\n",
    "\n",
    "At some point, *after you have trained and evaluated your classifier*, you might want to check how well your classification method can actually control the robot car. For this, you will need to wrap your trained classifier into a policy function that the simulator can use.\n",
    "\n",
    "This section will go over the details of\n",
    "* how to start the simulator;\n",
    "* how to implement a policy $f$;\n",
    "* how to analyse the rewards.\n",
    "\n",
    "\n",
    "### Running a simulation\n",
    "\n",
    "The function `run_simulation` below will setup a simulation of your robot on a given planet (`planet_id`) and track (`track_id`), and will use the policy `f` you provide to control the robot, for a maximum of `iterations` simulation steps. The simulation function can also show you the simulation in a popup-window (set `render=True`), or record all the (observation, actions) pairs (`record_data=True`).\n",
    "\n",
    "The function signature of run_simulation is:\n",
    "```\n",
    "rewards = run_simulation(f, iterations=500, planet_id=0, track_id=0, verbose=False, render=False, record_data=False, delay=0.0)\n",
    "    Run robot car simulation\n",
    "    Input arguments:\n",
    "    - f             # [function] the robot's policy function\n",
    "    - record_data   # [True/False] if true, return all (observation, action) pairs from the simulation \n",
    "    - planet_id     # [int] select the target planet (0=Earth, 1=Mars, 2=Saturn, 3=Neptune)\n",
    "    - track_id      # [int] select the target track on that planet (0, 1, 2, etc.)\n",
    "    - iterations    # [int] the maximum number of iterations N to run the simulation\n",
    "    - render        # [True/False] show the scene in a popup window (can be a bit slower)\n",
    "    - delay         # [float] a time delay that can be added to make the simulation run a bit slower\n",
    "    \n",
    "    Returns:\n",
    "    - rewards       # [numpy array of floats] all N rewards accumulated during the simulation\n",
    "    - observations  # [numpy array N x H x W x 3] N observations, each observation being a WxH 3-channel image\n",
    "    - actions       # [numpy array of ints] all N actions outputted by the given policy f\n",
    "    \n",
    "    Note: `observations` and `actions` are only returned if record_data=True\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f56f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user key input handler\n",
    "from pyglet.window import key\n",
    "import time\n",
    "\n",
    "# keep track if which keys have been pressed in the popup window\n",
    "# (will be used later for the human driver)\n",
    "KEY_PRESSED = {key.LEFT: False, key.RIGHT: False, key.UP: False, key.DOWN: False}\n",
    "\n",
    "def key_press(k, mod):\n",
    "    global STOP_SIMULATION, KEY_PRESSED\n",
    "    if k==key.ESCAPE: STOP_SIMULATION = True # set 'quit' flag if ESCAPE key is pressed\n",
    "    KEY_PRESSED[k] = True\n",
    "\n",
    "def key_release(k, mod):\n",
    "    global KEY_PRESSED\n",
    "    KEY_PRESSED[k] = False\n",
    "\n",
    "# define the set of all actions    \n",
    "ACTIONS = [0, 1, 2, 3, 4]\n",
    "ACTION_NAMES = ['noop', 'accel', 'left', 'right', 'brake']\n",
    "NUM_ACTIONS = 5 # number of distinct actions\n",
    "\n",
    "# A lookup table to convert the action class to an actual control input for the simulator (steer, accel, brake)\n",
    "ACTIONS_TO_CONTROL_INPUT = np.array([\n",
    "    [ 0,  0,  0   ], # 0 = do nothing\n",
    "    [ 0,  1,  0   ], # 1 = accelerate\n",
    "    [-1,  0,  0   ], # 2 = steer left\n",
    "    [ 1,  0,  0   ], # 3 = steer right\n",
    "    [ 0,  0,  0.25], # 4 = brake\n",
    "])\n",
    "\n",
    "def run_simulation(f, iterations=500, planet_id=0, track_id=0, verbose=False, render=False, record_data=False, delay=0.0):\n",
    "    \"\"\" Run robot car simulation\n",
    "    Input arguments:\n",
    "    - f             # [function] the robot's policy function\n",
    "    - record_data   # [True/False] if true, return all (observation, action) pairs from the simulation\n",
    "    - planet_id     # [int] select the target planet (0=Earth, 1=Mars, 2=Saturn, 3=Neptune)\n",
    "    - track_id      # [int] select the target track on that planet (0, 1, 2, etc.)\n",
    "    - iterations    # [int] the maximum number of iterations N to run the simulation\n",
    "    - render        # [True/False] show the scene in a popup window (can be a bit slower)\n",
    "    - delay         # [float] a time delay that can be added to make the simulation run a bit slower\n",
    "    \n",
    "    Returns:\n",
    "    - rewards       # [numpy array of floats] all N rewards accumulated during the simulation\n",
    "    - observations  # [numpy array N x H x W x 3] N observations, each observation being a WxH 3-channel image\n",
    "    - actions       # [numpy array of ints] all N actions outputted by the given policy f\n",
    "    \n",
    "    Note: `observations` and `actions` are only returned if record_data=True\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Starting simulation for {iterations} iterations.')\n",
    "    print('*** Press ESC key in popup window to stop the simulation! ***')\n",
    "    print()\n",
    "\n",
    "    # create a simulation environment on the given planet\n",
    "    planet = cr.PLANETS[planet_id]\n",
    "    env = cr.CarRacing(planet)\n",
    "    env.seed(track_id+planet_id*1455312) # set environment track generation seed based on planet_id and track_id\n",
    "\n",
    "    rewards = [] # will store the accumulated rewards\n",
    "    observations = [] # will store the accumulated observations (only if record_data==True)\n",
    "    actions = [] # will store the accumulated actions outputted by policy f (only if record_data==True)\n",
    "    \n",
    "    # reset KEY_PRESSED state at start of simulation\n",
    "    global KEY_PRESSED\n",
    "    KEY_PRESSED = {key.LEFT: False, key.RIGHT: False, key.UP: False, key.DOWN: False}\n",
    "    \n",
    "    # the STOP_SIMULATION flag will be set to True if user wants to interrupt the simulation\n",
    "    global STOP_SIMULATION\n",
    "    STOP_SIMULATION = False\n",
    "    completed_iterations = 0\n",
    "    \n",
    "    try:\n",
    "        # reset the simulation, and get the initial observation (robot \"sensor measurement\")\n",
    "        observation = env.reset()\n",
    "        \n",
    "        # ensure we can listen to user input in the popup window (e.g. to quit when pressing ESCAPE)\n",
    "        env.viewer.window.on_key_press = key_press\n",
    "        env.viewer.window.on_key_release = key_release\n",
    "        \n",
    "        # main simulation loop\n",
    "        for itr in range(iterations):\n",
    "            time.sleep(delay)\n",
    "            if STOP_SIMULATION: break\n",
    "                \n",
    "            # ** APPLYING YOUR POLICY **\n",
    "            # execute the given policy on the observation to determine the robot's action\n",
    "            action = f(observation)\n",
    "            \n",
    "            # sanity check: is the policy implemented correctly?\n",
    "            assert (isinstance(action, (int, np.integer))) # returned action should be a builtin or numpy integer\n",
    "            assert (action in ACTIONS) # action should be an integer 0, 1, 2, 3 or 4\n",
    "\n",
    "            # hard coded that for the first few iterations, the robot will always accelerate,\n",
    "            #   to avoid a poor policy from not moving the robot at all\n",
    "            if itr < 4: action = 1 # action 1 is accelerate\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'iteration {itr}: action = {ACTION_NAMES[action]}')\n",
    "\n",
    "            if record_data:\n",
    "                # only store all the observation and action pairs during the simulation\n",
    "                #   if the record_data argument is set to True\n",
    "                observations.append(observation)\n",
    "                actions.append(action)\n",
    "            \n",
    "            # ** EXECUTE ACTION ON ROBOT & GET OBSERVATION FOR NEXT TIME STEP **\n",
    "            ctrl_input = ACTIONS_TO_CONTROL_INPUT[action] \n",
    "\n",
    "            # execute simulation step with the given control input\n",
    "            observation, reward, environment_done, info = env.step(ctrl_input)\n",
    "            completed_iterations += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'iteration {itr}: reward = {reward}')\n",
    "\n",
    "            if render:\n",
    "                # update pop-window visualization\n",
    "                env.render()\n",
    "\n",
    "            # collect all rewards in a list\n",
    "            rewards.append(reward)\n",
    "    finally:\n",
    "        # make sure we always close the pop-up window,\n",
    "        # even if some exception is thrown during the main loop\n",
    "        env.close()\n",
    "        \n",
    "    rewards = np.array(rewards)\n",
    "    total_reward = np.sum(rewards)\n",
    "    \n",
    "    print(f'total reward after {completed_iterations} iterations: {total_reward}')\n",
    "    print(f'average reward: {total_reward/completed_iterations}')\n",
    "    \n",
    "    if record_data:\n",
    "        return rewards, np.array(observations), np.array(actions, dtype=int)\n",
    "        \n",
    "    # by default, only return the rewards\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239132f0",
   "metadata": {},
   "source": [
    "### Implementing a policy\n",
    "\n",
    "For the simulator, a policy $f(observation) \\rightarrow action$ should be implemented as a plain python function which takes a numpy array as input (the observation) and returns an integer (the action).\n",
    "So generally, a policy implementation would look like this:\n",
    "\n",
    "```python\n",
    "\n",
    "def f(observation):    \n",
    "    # Input: observation, a H x W x 3 numpy array containing an RGB image of the surroundings\n",
    "    # Output: action,     an integer representing the action (0 = NOOP, ... 5 = Brake)\n",
    "    # N.B.: actions is just an int, NOT a numpy array\n",
    "    \n",
    "    # YOUR CODE\n",
    "    #   convert observation to feature vector\n",
    "    #   predict action class given the feature vector using some ML technique\n",
    "    \n",
    "    return action\n",
    "```\n",
    "*Of course, don't name you policy just `f`, but give it some more descriptive name!*\n",
    "\n",
    "To illustrate, here is a dummy policy which just picks a random actions (without actually looking at the observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91446514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dummy policy\n",
    "def f_dummy(observation):\n",
    "    \"\"\" Dummy policy function, which just returns random action. \"\"\"\n",
    "    \n",
    "    # in this dummy policy, we ignore the observation and just select a random action\n",
    "    action = np.random.randint(0, NUM_ACTIONS)\n",
    "    \n",
    "    print(f'Received observation: {observation.shape} numpy array of type {observation.dtype}, returning action {action}')\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667f5a1",
   "metadata": {},
   "source": [
    "We can confirm that the policy returns a valid action label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad47b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (96, 96, 3) numpy array of type uint8, returning action 1\n"
     ]
    }
   ],
   "source": [
    "action = f_dummy(observations[0])\n",
    "\n",
    "# returned action should be a builtin int or a numpy integer (NOT a numpy array) in the range [0, 4]\n",
    "assert (isinstance(action, (int, np.integer)))\n",
    "assert (action in ACTIONS) # ACTIONS is the set of possible action labels, [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab36b3",
   "metadata": {},
   "source": [
    "### Reward\n",
    "\n",
    "To quantify how well a policy is working, the simulator will return the *rewards* that the robot car collected at each simulation step. The rewards determine how well you are doing in a race, and are based on the number of  segments of the track that the robot racer passes:\n",
    "\n",
    "* Everytime a new segments of the track is touched by your robot car, your robot receives a positive reward. You can see this in the visualization when a road segments's color changes to a lighter gray.\n",
    "* The robot car also get a tiny *negative* reward in each time step, as a penalty for spending time.\n",
    "* When the robot car goes off the track, it will not touch any new track segments and thus only collects negative rewards, but also the friction changes which makes the robot car more difficult to control.\n",
    "\n",
    "Overall, the goal is to cover as much of the race track as possible in the given number of simulation iterations. So, your robot car should go as fast as possible while staying on the track!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908609e",
   "metadata": {},
   "source": [
    "### Illustration of running the simulator with the dummy policy\n",
    "\n",
    "Let's try to run the simulation with the dummy policy, and render the output in the popup-window for the default number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d825fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # running the simulation with the dummy policy\n",
    "# rs = run_simulation(f_dummy, render=1, planet_id=0, track_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918c2c8",
   "metadata": {},
   "source": [
    "Clearly, this policy doesn't do anything particularly useful, and should make the robot car just slowly move forward. This policy will touch only few road segments, and therefore collect little positive reward.\n",
    "Let's visulize the rewards that the robot collected during the simulation.\n",
    "\n",
    "The first plot below shows when new parts of the track are reached and a large reward is collected. The second plot shows the total/cumulative reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "760569cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,4)) # create a wide figure (size 10) which is not so tall (size 4)\n",
    "# plt.subplot(1,2,1) # create subplot of 1 row, 2 columns, enable plotting in first cell\n",
    "# plt.plot(rs)\n",
    "# plt.xlabel('iteration')\n",
    "# plt.ylabel('reward')\n",
    "# plt.title('Reward per iteration')\n",
    "# plt.grid()\n",
    "\n",
    "# plt.subplot(1,2,2) # create subplot of 1 row, 2 columns, enable plotting in first cell\n",
    "# plt.plot(np.cumsum(rs)) # Cumulative sum of rewards\n",
    "# plt.xlabel('iteration')\n",
    "# plt.ylabel('total reward')\n",
    "# plt.title('Cumulative reward')\n",
    "# plt.grid()\n",
    "\n",
    "\n",
    "# print('Average reward:', np.mean(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e125f0",
   "metadata": {},
   "source": [
    "For comparing and evaluating classifiers, measure the performance of the classifiers themselves, i.e., the macro-F1 score.\n",
    "\n",
    "Still, the simulation and rewards can help you assess in what situations your robot AI is performing well, and when it is failing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c9f70",
   "metadata": {},
   "source": [
    "# Collecting new demonstrations\n",
    "\n",
    "At some point, you might want to collect more human demonstration data to make your method even beter.\n",
    "You can do this by:\n",
    "\n",
    "- manually controlling the robot car in the simulation yourself to generate new demonstrations\n",
    "- recording the resulting (observation, action) pairs during these demonstrations\n",
    "- saving the good demonstrations to disk to increase your example dataset\n",
    "\n",
    "The code below demonstrates how to do this. The idea is simple: just use the regular `run_simulation()` function, but use a special `f_human()` policy which simply returns the action based on the keyboard input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b00df200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a human driver\n",
    "def f_human(observation):\n",
    "    # Get the action obtained by the key_press/key_release callbacks from the popup window.\n",
    "    # Note that the human driver (you!) will of course see the environment image in the popup window,\n",
    "    # and ignore the 'observation' input of this function.\n",
    "    # This 'human policy' will therefore return your 'action' response to the visual input by checking\n",
    "    # which keyboard arrows you pressed.\n",
    "    \n",
    "    global KEY_PRESSED\n",
    "    \n",
    "    action = ACTION_NOOP\n",
    "    if KEY_PRESSED[key.LEFT]: action = ACTION_LEFT\n",
    "    elif KEY_PRESSED[key.RIGHT]: action = ACTION_RIGHT\n",
    "    elif KEY_PRESSED[key.UP]: action = ACTION_ACCEL\n",
    "    elif KEY_PRESSED[key.DOWN]: action = ACTION_BRAKE\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f9349",
   "metadata": {},
   "source": [
    "When we use this policy, ensure that the simulator stores and return all the (observation, action) pairs by setting the `record_data` argument of run_simulation to `True`.\n",
    "You can adjust the `planet_id` and `track_id` to get human driving responses on a variety of tracks in your training planet environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7cf477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# planet_id=0 # <-- CHANGE THIS to select the planet; can be 0, 1, 2\n",
    "# track_id=0  # <-- CHANGE THIS to select the track; can be any positive integer\n",
    "\n",
    "# rs, rec_obs, rec_actions = run_simulation(\n",
    "#     f_human,               # by using the 'human' policy, YOU determine the robot's actions based on what you see\n",
    "#     record_data=True,      # record and return all (observation, action) pairs from the simulation \n",
    "#     planet_id=planet_id,   # select the target planet\n",
    "#     track_id=track_id,     # select the target track on that planet (0, 1, 2, etc.)\n",
    "#     iterations=1000,       # maximum number of iterations to run the simulation\n",
    "#     render=True,           # when controling the car manually, it makes sense to render the scene\n",
    "#     delay=0.01             # adding a small delay will help you control the robot car\n",
    "# )\n",
    "# # Note: with delay=0.01 the simulation runs a bit slower, which makes it easier to give demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759d7a7",
   "metadata": {},
   "source": [
    "Explore the just collected samples in your latest recoding using an interactive slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8083ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_sample(idx, observations, actions):\n",
    "#     observation = observations[idx]\n",
    "#     action = actions[idx]\n",
    "#     plt.clf()\n",
    "#     plt.imshow(observation)\n",
    "#     plt.title(f'{idx}: {action}');\n",
    "    \n",
    "# ipywidgets.interactive(lambda idx: plot_sample(idx, rec_obs, rec_actions), idx=(0,rec_obs.shape[0]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cf8de",
   "metadata": {},
   "source": [
    "If you are unhappy with the the demonstration you gave, you can just execute the `run_simulation()` cell above again, until you are satisfied.\n",
    "\n",
    "To save the demonstration to disk, execute the cell below after setting `SAVE_DEMO` to True.\n",
    "\n",
    "**After you have saved the demonstration, don't forget to aftewards IMMEDIATELY set `SAVE_DEMO` back to False to avoid accidentally saving new demonstrations every time you rerun the notebook!!!**\n",
    "\n",
    "Note that the pickle filenames of your recordings will start with `demostud-`, while the originally provided demonstrations start with `demo-`. This makes it easy to load only the original, your, or both types of recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4e67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DEMO = False # <-- CHANGE THIS to 'True' to SAVE the last recording to disk!\n",
    "\n",
    "if SAVE_DEMO: \n",
    "    rec_N = rec_obs.shape[0]\n",
    "\n",
    "    demonstration = {\n",
    "        'observations': rec_obs,\n",
    "        'actions': rec_actions,\n",
    "        'planets': planet_id * np.ones(rec_N, dtype=int),\n",
    "        'tracks': track_id * np.ones(rec_N, dtype=int),\n",
    "    }\n",
    "    \n",
    "    # include date+time to filename in YYYYMMDD_HHMMSS format\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    dt_str = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Save to disk\n",
    "    save_filename = f'demonstrations/demostud-{planet_id}-{track_id}-{dt_str}.pickle'\n",
    "    print(f'Saving demonstation of planet {planet_id}, track {track_id} to {save_filename} ...')\n",
    "    with open(save_filename, 'wb') as fd:\n",
    "        pickle.dump(demonstration, fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f75fe",
   "metadata": {},
   "source": [
    "Ok, that completes the example code.\n",
    "Now it is your turn! Implement your solution to the final assignment below. For full points, make sure you address *all* the numbered items for each section, either by implementing something in code cells, or by providing text in Markdown cells. You are free to add as many code and markdown cells as required. Be sure to first read through all sections before you start, so you know what should go where. We are *not* using nbgrader for this final assignment.\n",
    "\n",
    "**When you are done, double check the \"Deliverables\" section at the start of this notebook on how to prepare your final submission!**\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edc05e",
   "metadata": {},
   "source": [
    "### ---\n",
    "\n",
    "# 1. Explore & Inspect the Data (5 points)\n",
    "Add code and markdown cells to address all of the following points:\n",
    "\n",
    "1. Create a visualization that shows three samples from each planet for which you have demonstrations\n",
    "2. Explain in words what you observe: how do the observations from the planets vary?\n",
    "3. Are the samples i.i.d.? What does that imply for splitting your data?\n",
    "4. Is there a class imbalance? If yes, what are procedures to deal with that?\n",
    "5. Do we have a high risk of conflicting labels for observations? What problems can this cause?\n",
    "6. The data was collected from human demonstrations. What are potential issues with this way of collecting data?\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7ff3c",
   "metadata": {},
   "source": [
    "### Show samples of the three planets\n",
    "\n",
    "Inspecting the training data is very important before starting to build a Machine Learning model. Having a clear overview of the characteristics your data samples enables one to obtain an appropriate trainnig method. This entails knowing the values, shapes, distributions and other properties of the data samples. The data samples for this assignment are colored pixels. Each observation is a 96x96x3 array, namely 3 RGB values per pixel and 96x96 pixels per observation. \n",
    "\n",
    "The code below plots three different track samples on the three different planets. The observations from different planets only vary in the color of the background. In the next cell block, the class distribution is calculated. The class distribution shows a class imbalance, which means that attention should be paid to selecting the training data. In order to train our models sufficiently, the imbalance should be reduced. This is done by filtering the data based on their label: keeping count of the distribution of the class labels resulted in a more evenly distributed training data over the classes.\n",
    "\n",
    "Each sample is the result of a human controller racing through various tracks. The samples are not correlated (i.e. the label of one sample does not influence the label of another sample) and therefore the data is independent. After inspecting the class distributions, it becomes obvious the data samples are not identically distributed over the classes. To make up for this, not only the training data was filtered by class, but also the training data is shuffled before training the classifiers.\n",
    "\n",
    "There is a risk of conflicting certain labels for observations, namely the labels (0) - Do nothing and (1) - Accelerate. If the road is curved left or right, the corresponding action should not easily classifiable. However, on a straight road, both accelerating and doing nothing are good options and might be interchanged by the classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ef75732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 15))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(observations[200])\n",
    "plt.title('Sample of a racing track on Earth')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(observations[1100])\n",
    "plt.title('Sample of a racing track on Mars')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(observations[1300])\n",
    "plt.title('Sample of a racing track on Saturn');\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbed5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classed are distributed as: [7014 3179 2932 1815   60]\n"
     ]
    }
   ],
   "source": [
    "class_distribution = np.bincount(actions)\n",
    "print('The classed are distributed as:', class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1a0f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Prepare the Data and Evaluate Features (15 points)\n",
    "\n",
    "In this section you should pre-process the data, e.g., down-sample, and extract features to create your training data matrix \"X\".\n",
    "\n",
    "\n",
    "## 2.1. Clustering observations from planets\n",
    "\n",
    "Before we turn towards the main task of action classification (section 2.2), let us first try a small unsupervised clustering task. Pretend that we only have the observations, but did not record the planet_ids of these observations. The goal is to cluster the observations into k=3 clusters such that 1 cluster (approximately) corresponds to 1 planet. For this task, you can ignore the actions and track_id information.\n",
    "\n",
    "1. Propose a feature extraction method `feat_extract_clust` which can be used to CLUSTER the samples and (approximately) recover the planet_ids. Motivate what you use in your feature extraction method.\n",
    "2. Perform clustering based on the features obtained with `feat_extract_clust`, and compare the results to the true planet_id labels. For this you will need to select a statistical measure to compare cluster labels to planet_ids.\n",
    "3. Explain what measure you use for comparing the features and why.\n",
    "4. Can you recuperate the planet_ids by clustering? Motivate your answer with your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0cfcd",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "The observations from different planets show the most variance in background color. In order to cluster the samples, the average color of each sample is calculated. The samples are now only 3-dimensional, which we can visualize by plotting in 3D using the following functions (which we imported from previous assignments). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f784a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "def make_3d_plot_axes_equal(ax):\n",
    "    \"\"\" Utility function to make axes equally scaled for 3D plots in matplotlib.\n",
    "        Note that for 2D plots we can simply use ax.axes('equal'),\n",
    "        but unfortunately this doesn't work for 3D plots, so we use this utility function.\n",
    "        \n",
    "        Inspired by: https://stackoverflow.com/a/31364297\n",
    "    \"\"\" \n",
    "    \n",
    "    ax_limits = np.array([ax.get_xlim3d(), ax.get_ylim3d(), ax.get_zlim3d()]).T\n",
    "    \n",
    "    m = ax_limits.mean(axis=0)\n",
    "    max_range = (ax_limits - m).max();\n",
    "    \n",
    "    ax.set_xlim(m[0] - max_range, m[0] + max_range)\n",
    "    ax.set_ylim(m[1] - max_range, m[1] + max_range)\n",
    "    ax.set_zlim(m[2] - max_range, m[2] + max_range)\n",
    "\n",
    "def plot_3d_data(X, view_angle1, view_angle2, label_name='dim'):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.view_init(view_angle1, view_angle2)\n",
    "    \n",
    "    ax.scatter(X[:,0], X[:,1], X[:,2], s=5., alpha=0.7)\n",
    "\n",
    "    plt.xlabel(label_name+' 0')\n",
    "    plt.ylabel(label_name+' 1')\n",
    "    ax.zaxis.set_label_text(label_name+' 2') # no plt.zlabel() :-/\n",
    "\n",
    "    # ensure 3D plot has equally scaled axes\n",
    "    make_3d_plot_axes_equal(ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814d3de",
   "metadata": {},
   "source": [
    "### Prepare data and plot with ipywidgets\n",
    "In the code cell below we calculated the average color of each instance, and plotted all instances in 3D. In this plot, 3 clusters are very clearly distinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a993907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cbb23ad8cf4db08445be5c15a9566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='view_angle1', max=90), IntSlider(value=180, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data\n",
    "image_avgs = []\n",
    "for i in range(len(observations)):\n",
    "    image_avgs.append(np.average(np.average(observations[i], axis = 1), axis = 0))\n",
    "\n",
    "image_avgs = np.array(image_avgs)\n",
    "\n",
    "# Plot data with simple widgets\n",
    "ipywidgets.interactive(\n",
    "    lambda view_angle1, view_angle2: plot_3d_data(image_avgs, view_angle1, view_angle2, label_name='feature'),\n",
    "    view_angle1=(0, 90),\n",
    "    view_angle2=(0, 360)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6369a5",
   "metadata": {},
   "source": [
    "### Use K-Means to find clusters centers\n",
    "In de code cell below we calculated the average color of each instance, and plotted all instances in 3D. In this plot, 3 clusters are very clearly distinguishable. Since our clusters are seperated and do not overlap, it is easy to get a high accuracy using a simple clustering method like KMeans. This clustering algorithm searches for 3 clusters which is does with 100% accuracy since there is no overlap between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdf0e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "The accuracy score for this clustering method is:,  73.33333333333333 %\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606a419105e24c93aaeb86498bfa1a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='view_angle1', max=90), IntSlider(value=180, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 3, random_state=0)\n",
    "y_pred = kmeans.fit_predict(image_avgs)\n",
    "\n",
    "kmeans.cluster_centers_\n",
    "\n",
    "print(planet_ids)\n",
    "print(kmeans.labels_)\n",
    "print(\"The accuracy score for this clustering method is:, \", np.count_nonzero(planet_ids == y_pred)/len(y_pred)*100, \"%\")\n",
    "\n",
    "\n",
    "def plot_data_with_labels(X, y=None, view_angle1=None, view_angle2=None):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(view_angle1, view_angle2)\n",
    "    ax.scatter(X[:,0], X[:,1], X[:,2], s=5., alpha=0.7, c=y)  \n",
    "    ax.set_xlabel('red')\n",
    "    ax.set_ylabel('green')\n",
    "    ax.set_zlabel('blue')\n",
    "        \n",
    "ipywidgets.interactive(\n",
    "    lambda view_angle1, view_angle2: plot_data_with_labels(image_avgs, y_pred, view_angle1, view_angle2),\n",
    "    view_angle1=(0, 90),\n",
    "    view_angle2=(0, 360)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d5957",
   "metadata": {},
   "source": [
    "## 2.2. Features for action classification\n",
    "\n",
    "Now we turn to feature exration for the main classification task, which you can reuse also in the later sections of this notebook.\n",
    "\n",
    "1. Explain: Will you use the same extractor as in step 1; Why (not)?\n",
    "2. Propose a feature extraction method `feat_extract` which you will use in the subsequent sections to classify *action*, rather than planet_ids.\n",
    "3. Explain: Are there any important hyperparameters in your feature extractor?\n",
    "4. Explain: How will you decide on the values for these hyperparameters? What is the trade-off if this hyperparameter is either (too) low or (too) high?\n",
    "5. Explain: What is the dimensionality of your feature space?\n",
    "6. Apply your `feat_extract` to all observations to create the data that you will use in the subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c93ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.transform import downscale_local_mean\n",
    "from skimage import filters\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a1e43",
   "metadata": {},
   "source": [
    "Like mentioned before there is a class inbalance. Therefore a function is written to distribute the data according to desired parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bfa856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribute the action classes for the training class\n",
    "def distribute(X, y, a, b, c, d, e, obs):\n",
    "    observations_distributed = []\n",
    "    actions_distributed = []\n",
    "    action_count = [a, b, c, d, e]\n",
    "    for i in range(len(X)):\n",
    "        if action_count[y[i]] < obs:\n",
    "            action_count[y[i]] += 1\n",
    "            observations_distributed.append(X[i])\n",
    "            actions_distributed.append(y[i])\n",
    "    observations_distributed = np.array(observations_distributed)\n",
    "    actions_distributed = np.array(actions_distributed)\n",
    "    return observations_distributed, actions_distributed\n",
    "\n",
    "earth_observations_distributed, earth_actions_distributed = distribute(earth_observations, earth_actions, 0, 400, 650, 650, 0, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a4c86",
   "metadata": {},
   "source": [
    "The objective is now to classify a certain action based on the shape of the road ahead. The color of the background should not affect the prediction of the class, and is therefore of no interest anymore. A different feature extraction method should be used for action classification. The feature extraction consists of different substeps:\n",
    "\n",
    "- Cutting the image\n",
    "- Grayscaling the image\n",
    "- Applying a Sobel filter\n",
    "\n",
    "First we cut the image to a smaller size, since the model does not need the whole observation to determine an action. The classifier only needs to see a small part of the road ahead in order to estimate wheter a turn is coming. Next, we apply a gray filter over all samples to reduce the dimensionality of the data set by a factor 3: each pixel now only contains 1 value between zero and 1 instead of 3 RGB values. To filter out irrelevant features we applied a Roberts filter, which creates a differential map of the observation which shows the gradient of the observation, i.e. where pixels are varying compared to neighbouring pixels. The observations now only show the boundaries of the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df7e1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 3600)\n"
     ]
    }
   ],
   "source": [
    "def feat_extract(X):\n",
    "    gray = rgb2gray(X)[:,20:80,20:80]\n",
    "    obs_filter = np.zeros(gray.shape)\n",
    "    for i in range(len(X)):\n",
    "        obs_filter[i] = filters.sobel(gray[i])\n",
    "    obs_filter = obs_filter.reshape(obs_filter.shape[0], obs_filter.shape[1]*obs_filter.shape[2]) \n",
    "    return obs_filter\n",
    "\n",
    "def feature_vector(X):\n",
    "    gray = rgb2gray(X)[20:80,20:80]\n",
    "    obs_filter = filters.sobel(gray)\n",
    "    obs_filter = obs_filter.reshape(1, obs_filter.shape[0]*obs_filter.shape[1]) \n",
    "    return obs_filter\n",
    "\n",
    "X_earth_red = feat_extract(earth_observations_distributed)\n",
    "# print(earth_actions.shape)\n",
    "print(X_earth_red.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d131ef",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# 3. Single Planet Action Classification  (35 points)\n",
    "To get started, we will train and test a model that is only suitable for racing on a single planet, i.e., on Earth (planet 0)\n",
    "\n",
    "As a first step split the data into a training, validation, and test set. You can use the provided data, or collect your own.\n",
    "\n",
    "## 3.1. Shortlist Promising Models\n",
    "1. Compare at least 2 models. One of them needs to be a neural network, one of them needs to be not a neural network.\n",
    "2. For each of the models that you are going to compare, explain what are its relative advantages/disadvantages in terms of training time, test time, and number of model parameters compared to the other choices. Also explain how these considerations relate to the target application, and motivate which type of model would be preferred based on these considerations only (so disregarding the actual quality of the models).\n",
    "3. If needed, perform dimensionality reduction before training your selection models. Expain why it is (not) needed.\n",
    "4. Roughly tune those models\n",
    "5. Evaluate the models in terms of performance, bias, variance, etc.\n",
    "6. Please use the macro-F1 score (see sklearn documentation) as your main criterion. Looking at confusion matrices, accuracy etc. might also provide valuable insights. Why is the accuracy score potentially problematic in this setting?\n",
    "7. Pick one algorithm to develop further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3b403",
   "metadata": {},
   "source": [
    "### Promising Models\n",
    "\n",
    "Three models that were initially tested are:\n",
    "\n",
    "- Random Forest Classifier\n",
    "- Neural Network\n",
    "\n",
    "The Random Forest classifiers is overall well-known for its low computational time and high accuracy in general. A neural network is different from the previous models as it is able to learn and model complex patterns in data samples. Furthermore it has the ability to generalize and make accurate predictions on data sets it has never seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233306c",
   "metadata": {},
   "source": [
    "### Splitting the data in a training, validation and test set\n",
    "In order to evaluate the model performance, a validation and a test set are needed. The validation set is just like a test set, which can be used to evaluate performance without using the test set. The test set should not be touched untill the final evaluation, otherwise one would be using the test set to tweak the hyperparamters, which results in an unrealistic performance on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a58da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_earth, X_notTrain, y_train_earth, y_notTrain = train_test_split(X_earth_red, earth_actions_distributed, test_size=0.25, random_state=0)\n",
    "X_test_earth, X_val_earth, y_test_earth, y_val_earth = train_test_split(X_notTrain, y_notTrain, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f6915",
   "metadata": {},
   "source": [
    "### Dimensionality reduction using PCA\n",
    "\n",
    "After feature extraction, the feature space is still quite large. The feature vectors have a length of 3600 features. To reduce the computational load, PCA is applied to reduce the amount of dimensions by selecting and preserving the features which show the most variance. The hyperparameter n_componenets determines how many dimensions are desired in de resulting dataset. If a value between 0 and 1 is given, like 0.95, PCA computes the minimum number of dimension required to preserve 95% of the training set's variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d20f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "\n",
    "X_train_earth_pca = pca.fit_transform(X_train_earth)\n",
    "X_val_earth_pca = pca.transform(X_val_earth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99672e5b",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b72aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def eval_classifier(clf, X, y):\n",
    "    y_pred = rf_clf.predict(X)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_pred) \n",
    "    confmat =  confusion_matrix(y, y_pred)\n",
    "    f1score = f1_score(y, y_pred, average='macro')\n",
    "    return accuracy, confmat, f1score\n",
    "\n",
    "#Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_earth)\n",
    "X_val_scaled = scaler.fit_transform(X_val_earth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc42d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6875, array([[109,   3,   5,   7],\n",
      "       [ 44,  34,   1,   2],\n",
      "       [ 17,   0,  35,   0],\n",
      "       [ 11,   0,   0,  20]], dtype=int64), 0.6775950308777527)\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=1, class_weight = 'balanced')\n",
    "rf_clf.fit(X_train_scaled, y_train_earth)\n",
    "\n",
    "print(eval_classifier(rf_clf, X_val_scaled, y_val_earth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b2b11",
   "metadata": {},
   "source": [
    "The Random Forest classifier obtains a F1 score of 0.677. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c421b14",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "In this part of the assignment a neural network is build and evaluated. A neural network consists of a variable amount of layers and neurons in each layer. The design and size of a neural network is dependent on the classification task. The layers in this assignments neural network are:\n",
    "- Input Layer: The amount of neurons in the input layer is equal to the amount of features in the feature vector.\n",
    "- Hidden Layers: The amount of hidden layers typically varies between 1 and 5. The amount of hidden layers for this network is based on a similar classification task, namely the classification of the Fashion MNIST dataset which uses 2 hidden layers. The number of neurons in each hidden layer varies between 10 and 100. Again, the initial amount was copied from the Fashion MNIST example\n",
    "- Output Layer: The amount of neurons in the output layer is determined by the amount of different class labels.\n",
    "\n",
    "For this multiclass classification problem, 'ReLu' activation is used to avoid vanishing gradient problems. The output activation function is set to 'softmax', to convert a vector of numbers (input for the last layer) to a vector of probabilities (output of the last layer). Based on these probabilities, the model makes a prediction for each observation entered in the input layer of the network.\n",
    "\n",
    "The optimization of the neural network can be done using various methods, like Gradient Descend, Momentum, Adam etc. Adam is an optimizer which is a combination of AdaGrad and Momentum. Adam has the best of both worlds and is therefore able to quickly find a minimum in de loss function.\n",
    "\n",
    "Early stopping is a regularization technique which is added to prevent the neural network from overfitting. If the validation loss (which should decrease during the training) stops decreasing and starts increasing, it is no longer useful to keep on training the network. Without stopping early, the model will start to overfit which increases the validation loss. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57ff07f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b60b2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_orig):\n",
    "    y_one_hot = keras.utils.to_categorical(y_orig)\n",
    "    y_one_hot = y_one_hot.astype(np.uint8)\n",
    "    return y_one_hot\n",
    "\n",
    "y_one_hot_train = one_hot_encoding(y_train_earth)\n",
    "y_one_hot_val = one_hot_encoding(y_val_earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ae42241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"learned_weights/weights.best.hdf5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_freq='epoch',\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73686232",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_units = len(X_train_earth_pca[1])\n",
    "num_logits = len(np.unique(y_train_earth))\n",
    "NNH = 18\n",
    "metrics = ['accuracy']   \n",
    "validation_split = 0.2\n",
    "epochs    = 30\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a51ce41e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(1)\n",
    "\n",
    "def neural_network(n_hidden=2, n_neurons=NNH, learning_rate=learning_rate, metrics = metrics):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for i in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(NNH, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.15))\n",
    "    model.add(tf.keras.layers.Dense(num_logits, activation='softmax'))\n",
    "    optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=metrics)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a43b3061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 1380 samples, validate on 345 samples\n",
      "Epoch 1/30\n",
      "1380/1380 [==============================] - 0s 229us/sample - loss: 1.2715 - acc: 0.4877 - val_loss: 1.1706 - val_acc: 0.5159\n",
      "Epoch 2/30\n",
      "1380/1380 [==============================] - 0s 143us/sample - loss: 1.0899 - acc: 0.6188 - val_loss: 1.0919 - val_acc: 0.5797\n",
      "Epoch 3/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 1.0417 - acc: 0.6268 - val_loss: 1.0404 - val_acc: 0.6000\n",
      "Epoch 4/30\n",
      "1380/1380 [==============================] - 0s 132us/sample - loss: 1.0135 - acc: 0.6261 - val_loss: 1.0431 - val_acc: 0.5884\n",
      "Epoch 5/30\n",
      "1380/1380 [==============================] - 0s 137us/sample - loss: 1.0042 - acc: 0.6377 - val_loss: 1.0120 - val_acc: 0.6029\n",
      "Epoch 6/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 0.9910 - acc: 0.6457 - val_loss: 0.9979 - val_acc: 0.6087\n",
      "Epoch 7/30\n",
      "1380/1380 [==============================] - 0s 132us/sample - loss: 0.9694 - acc: 0.6449 - val_loss: 1.0177 - val_acc: 0.6058\n",
      "Epoch 8/30\n",
      "1380/1380 [==============================] - 0s 129us/sample - loss: 0.9817 - acc: 0.6428 - val_loss: 1.0141 - val_acc: 0.6087\n",
      "Epoch 9/30\n",
      "1380/1380 [==============================] - 0s 128us/sample - loss: 0.9916 - acc: 0.6442 - val_loss: 1.0902 - val_acc: 0.5565\n",
      "Epoch 10/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 0.9754 - acc: 0.6609 - val_loss: 0.9913 - val_acc: 0.6319\n",
      "Epoch 11/30\n",
      "1380/1380 [==============================] - 0s 131us/sample - loss: 0.9742 - acc: 0.6710 - val_loss: 1.0076 - val_acc: 0.6290\n",
      "Epoch 12/30\n",
      "1380/1380 [==============================] - 0s 133us/sample - loss: 0.9511 - acc: 0.6855 - val_loss: 1.0134 - val_acc: 0.6319\n",
      "Epoch 13/30\n",
      "1380/1380 [==============================] - 0s 136us/sample - loss: 0.9600 - acc: 0.6710 - val_loss: 1.0188 - val_acc: 0.6261\n",
      "Epoch 14/30\n",
      "1380/1380 [==============================] - 0s 128us/sample - loss: 0.9440 - acc: 0.6819 - val_loss: 1.0017 - val_acc: 0.6319\n",
      "Epoch 15/30\n",
      "1380/1380 [==============================] - 0s 127us/sample - loss: 0.9425 - acc: 0.6855 - val_loss: 1.0417 - val_acc: 0.6116\n",
      "Epoch 16/30\n",
      "1380/1380 [==============================] - 0s 124us/sample - loss: 0.9630 - acc: 0.6884 - val_loss: 0.9950 - val_acc: 0.6261\n",
      "Epoch 17/30\n",
      "1380/1380 [==============================] - 0s 130us/sample - loss: 0.9510 - acc: 0.6964 - val_loss: 0.9959 - val_acc: 0.6522\n",
      "Epoch 18/30\n",
      "1380/1380 [==============================] - 0s 136us/sample - loss: 0.9208 - acc: 0.7022 - val_loss: 0.9699 - val_acc: 0.6290\n",
      "Epoch 19/30\n",
      "1380/1380 [==============================] - 0s 132us/sample - loss: 0.9048 - acc: 0.6928 - val_loss: 1.0328 - val_acc: 0.6174\n",
      "Epoch 20/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 0.9373 - acc: 0.7029 - val_loss: 1.0268 - val_acc: 0.6522\n",
      "Epoch 21/30\n",
      "1380/1380 [==============================] - 0s 132us/sample - loss: 0.9196 - acc: 0.6884 - val_loss: 1.0231 - val_acc: 0.6377\n",
      "Epoch 22/30\n",
      "1380/1380 [==============================] - 0s 136us/sample - loss: 0.9137 - acc: 0.6833 - val_loss: 0.9752 - val_acc: 0.6377\n",
      "Epoch 23/30\n",
      "1380/1380 [==============================] - 0s 124us/sample - loss: 0.9495 - acc: 0.6899 - val_loss: 1.0365 - val_acc: 0.6348\n",
      "Epoch 24/30\n",
      "1380/1380 [==============================] - 0s 132us/sample - loss: 0.8913 - acc: 0.7014 - val_loss: 1.0181 - val_acc: 0.6232\n",
      "Epoch 25/30\n",
      "1380/1380 [==============================] - 0s 121us/sample - loss: 0.9165 - acc: 0.7072 - val_loss: 1.0514 - val_acc: 0.6348\n",
      "Epoch 26/30\n",
      "1380/1380 [==============================] - 0s 129us/sample - loss: 0.9455 - acc: 0.6819 - val_loss: 1.0299 - val_acc: 0.6319\n",
      "Train on 1380 samples, validate on 345 samples\n",
      "Epoch 1/30\n",
      "1380/1380 [==============================] - 0s 239us/sample - loss: 1.2471 - acc: 0.5152 - val_loss: 1.0946 - val_acc: 0.5652\n",
      "Epoch 2/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 1.0743 - acc: 0.5920 - val_loss: 1.0919 - val_acc: 0.5652\n",
      "Epoch 3/30\n",
      "1380/1380 [==============================] - 0s 128us/sample - loss: 1.0294 - acc: 0.6101 - val_loss: 1.0761 - val_acc: 0.5768\n",
      "Epoch 4/30\n",
      "1380/1380 [==============================] - 0s 130us/sample - loss: 1.0173 - acc: 0.6196 - val_loss: 1.0150 - val_acc: 0.6029\n",
      "Epoch 5/30\n",
      "1380/1380 [==============================] - 0s 128us/sample - loss: 0.9969 - acc: 0.6435 - val_loss: 1.0202 - val_acc: 0.5971\n",
      "Epoch 6/30\n",
      "1380/1380 [==============================] - 0s 138us/sample - loss: 0.9525 - acc: 0.6594 - val_loss: 0.9966 - val_acc: 0.6290\n",
      "Epoch 7/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 0.9822 - acc: 0.6442 - val_loss: 1.0095 - val_acc: 0.5942\n",
      "Epoch 8/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 0.9449 - acc: 0.6580 - val_loss: 0.9825 - val_acc: 0.6203\n",
      "Epoch 9/30\n",
      "1380/1380 [==============================] - 0s 126us/sample - loss: 0.9371 - acc: 0.6681 - val_loss: 1.0140 - val_acc: 0.6058\n",
      "Epoch 10/30\n",
      "1380/1380 [==============================] - 0s 125us/sample - loss: 0.9542 - acc: 0.6536 - val_loss: 1.0066 - val_acc: 0.5971\n",
      "Epoch 11/30\n",
      "1380/1380 [==============================] - 0s 137us/sample - loss: 0.9312 - acc: 0.6601 - val_loss: 0.9719 - val_acc: 0.6116\n",
      "Epoch 12/30\n",
      "1380/1380 [==============================] - 0s 145us/sample - loss: 0.9231 - acc: 0.6768 - val_loss: 0.9658 - val_acc: 0.6145\n",
      "Epoch 13/30\n",
      "1380/1380 [==============================] - 0s 134us/sample - loss: 0.9233 - acc: 0.6841 - val_loss: 1.0097 - val_acc: 0.6261\n",
      "Epoch 14/30\n",
      "1380/1380 [==============================] - ETA: 0s - loss: 0.8992 - acc: 0.688 - 0s 135us/sample - loss: 0.8986 - acc: 0.6899 - val_loss: 1.0167 - val_acc: 0.6551\n",
      "Epoch 15/30\n",
      "1380/1380 [==============================] - 0s 133us/sample - loss: 0.9174 - acc: 0.6870 - val_loss: 1.0179 - val_acc: 0.6580\n",
      "Epoch 16/30\n",
      "1380/1380 [==============================] - 0s 124us/sample - loss: 0.9315 - acc: 0.6935 - val_loss: 0.9855 - val_acc: 0.6406\n",
      "Epoch 17/30\n",
      "1380/1380 [==============================] - 0s 129us/sample - loss: 0.9032 - acc: 0.6754 - val_loss: 0.9708 - val_acc: 0.6522\n",
      "Epoch 18/30\n",
      "1380/1380 [==============================] - 0s 122us/sample - loss: 0.9039 - acc: 0.7043 - val_loss: 1.0104 - val_acc: 0.6319\n",
      "Epoch 19/30\n",
      "1380/1380 [==============================] - 0s 128us/sample - loss: 0.9197 - acc: 0.6645 - val_loss: 0.9835 - val_acc: 0.6493\n",
      "Epoch 20/30\n",
      "1380/1380 [==============================] - 0s 129us/sample - loss: 0.8897 - acc: 0.6971 - val_loss: 1.0328 - val_acc: 0.6145\n"
     ]
    }
   ],
   "source": [
    "# Prevent overfitting with early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
    "nn = neural_network()\n",
    "nn.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\n",
    "\n",
    "init_neural_network = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history = init_neural_network.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a23b1c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3acad",
   "metadata": {},
   "source": [
    "## 3.2. Fine-Tune the System\n",
    "1. What are the most important hyperparameters of your chosen algorithm?\n",
    "2. Perform hyperparameter optimization (including pre-processing steps)\n",
    "3. Compare at least 3 models with different sets of hyperparameters \n",
    "4. Evaluate the final model (similar to “Shortlist Promising Models” above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbfb901",
   "metadata": {},
   "source": [
    "### Fine-Tuning the neural network\n",
    "The most important hyperparameters for the Neural Network are:\n",
    "\n",
    "- Learning rate \n",
    "- Network topology\n",
    "- Activation function\n",
    "\n",
    "The learning rate plays a role in the gradient descend of training a neural network, which enables the neural network to find a minimum in the loss function. If the learning rate has a high value, gradient descend takes (too) large steps and might converge to a suboptimal minimum too quickly. If the learning rate is too small however, training will progress very slowly as the updates to the weights and biases in the network are tiny. \n",
    "\n",
    "By randomly entering values for the hyperparameters, an optimal combination of hyperparameters can be approached. \n",
    "\n",
    "Default values of the neural network:\n",
    "- Learning rate = 0.01\n",
    "- Neurons in each layer = 20\n",
    "- Activation function = 'ReLU'\n",
    "\n",
    "Another way of finding the optimal values for hyperparameters is using the RandomSearchCV function from sklearn. \n",
    "\n",
    "Varying the Learning Rate:\n",
    "\n",
    "- For a learning rate of 0.1, the validation accuracy was 0.6238 and the validation loss was 1.0741.\n",
    "- For a learning rate of 0.001, the validation accuracy was 0.6740 and the validation loss was 1.0421.\n",
    "- For a learning rate of 0.0001, the validation accuracy was 0.6928 and the validation loss was 1.014.\n",
    "\n",
    "Varying the Network Topology:\n",
    "\n",
    "- Using 10 neurons in each layer, the validation accuracy was 0.67 and the validation loss was 0.997.\n",
    "- Using 50 neurons in each layer, the validation accuracy was 0.636 and the validation loss was 1.000.\n",
    "- Using 100 neurons in each layer, the validation accuracy was 0.627 and the validation loss was 1.0422.\n",
    "\n",
    "Varying the activation function:\n",
    "\n",
    "- Using the activation functin 'sigmoid', the validation accuracy was 0.693 and the validation loss was 0.975.\n",
    "- Using the activation functin 'tanh', the validation accuracy was 0.627 and the validation loss was 1.0381.\n",
    "- Using the activation functin 'ReLU', the validation accuracy was 0.655 and the validation loss was 1.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e86175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# # Adapting learning rate\\nearly_stopping = keras.callbacks.EarlyStopping(patience=8)\\n\\n#Learning rate 1\\nlearning_rate = 0.01\\nkeras_iteration1lr = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_lr1 = keras_iteration1lr.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\\n\\n#Learning rate 1\\nlearning_rate = 0.0001\\nkeras_iteration2lr = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_lr2 = keras_iteration2lr.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\\n\\n#Learning rate 1\\nlearning_rate = 0.00001\\nkeras_iteration3lr = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_lr3 = keras_iteration3lr.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# # Adapting learning rate\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
    "\n",
    "#Learning rate 1\n",
    "learning_rate = 0.01\n",
    "keras_iteration1lr = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_lr1 = keras_iteration1lr.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\n",
    "\n",
    "#Learning rate 1\n",
    "learning_rate = 0.0001\n",
    "keras_iteration2lr = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_lr2 = keras_iteration2lr.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "#Learning rate 1\n",
    "learning_rate = 0.00001\n",
    "keras_iteration3lr = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_lr3 = keras_iteration3lr.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc2ed51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#PLOT RESULTS\\nplt.figure(1)\\nplt.plot(history_lr1.history[\\'val_acc\\'], \\'r\\', label=\\'val_accuracy\\')\\nplt.plot(history_lr1.history[\\'acc\\'], \\'y\\', label=\\'accuracy\\')\\nplt.plot(history_lr1.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_lr1.history[\\'val_loss\\'] , \\'g\\', label=\\'val_loss\\')\\nplt.title(\"learning_rate = 0.01\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()\\n\\nplt.figure(2)\\nplt.plot(history_lr2.history[\\'val_acc\\'], \\'r\\',label=\\'val_acc\\')\\nplt.plot(history_lr2.history[\\'acc\\'],\\'y\\', label=\\'accuracy\\')\\nplt.plot(history_lr2.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_lr2.history[\\'val_loss\\'], \\'g\\',label=\\'val_loss\\')\\nplt.title(\"learning_rate = 0.0001\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()\\n\\n\\nplt.figure(3)\\nplt.plot(history_lr3.history[\\'val_acc\\'], \\'r\\',label=\\'val_accuracy\\')\\nplt.plot(history_lr3.history[\\'acc\\'], \\'y\\',label=\\'accuracy\\')\\nplt.plot(history_lr3.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_lr3.history[\\'val_loss\\'] , \\'g\\',label=\\'val_loss\\')\\nplt.title(\"learning_rate = 0.00001\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#PLOT RESULTS\n",
    "plt.figure(1)\n",
    "plt.plot(history_lr1.history['val_acc'], 'r', label='val_accuracy')\n",
    "plt.plot(history_lr1.history['acc'], 'y', label='accuracy')\n",
    "plt.plot(history_lr1.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_lr1.history['val_loss'] , 'g', label='val_loss')\n",
    "plt.title(\"learning_rate = 0.01\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history_lr2.history['val_acc'], 'r',label='val_acc')\n",
    "plt.plot(history_lr2.history['acc'],'y', label='accuracy')\n",
    "plt.plot(history_lr2.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_lr2.history['val_loss'], 'g',label='val_loss')\n",
    "plt.title(\"learning_rate = 0.0001\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(history_lr3.history['val_acc'], 'r',label='val_accuracy')\n",
    "plt.plot(history_lr3.history['acc'], 'y',label='accuracy')\n",
    "plt.plot(history_lr3.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_lr3.history['val_loss'] , 'g',label='val_loss')\n",
    "plt.title(\"learning_rate = 0.00001\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "314c1f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# # Adapting loss function\\nlearning_rate = 0.001 # set learning_rate back to 0.001\\n\\nprint('Default activation function is relu')\\n\\n# sigmoid\\nactivation = 'sigmoid'\\nkeras_iteration1ac = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_act1 = keras_iteration1ac.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\\n\\n# tanh\\nactivation = 'tanh'\\nkeras_iteration2ac = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_act2 = keras_iteration2ac.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# # Adapting loss function\n",
    "learning_rate = 0.001 # set learning_rate back to 0.001\n",
    "\n",
    "print('Default activation function is relu')\n",
    "\n",
    "# sigmoid\n",
    "activation = 'sigmoid'\n",
    "keras_iteration1ac = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_act1 = keras_iteration1ac.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\n",
    "\n",
    "# tanh\n",
    "activation = 'tanh'\n",
    "keras_iteration2ac = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_act2 = keras_iteration2ac.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55f35a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#PLOT RESULTS\\nplt.figure(1)\\nplt.plot(history_act1.history[\\'val_acc\\'], \\'r\\', label=\\'val_accuracy\\')\\nplt.plot(history_act1.history[\\'acc\\'], \\'y\\', label=\\'accuracy\\')\\nplt.plot(history_act1.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_act1.history[\\'val_loss\\'] , \\'g\\', label=\\'val_loss\\')\\nplt.title(\"activation = sigmoid\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()\\n\\nplt.figure(2)\\nplt.plot(history_act2.history[\\'val_acc\\'], \\'r\\',label=\\'val_acc\\')\\nplt.plot(history_act2.history[\\'acc\\'],\\'y\\', label=\\'accuracy\\')\\nplt.plot(history_act2.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_act2.history[\\'val_loss\\'], \\'g\\',label=\\'val_loss\\')\\nplt.title(\"activation = tanh\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#PLOT RESULTS\n",
    "plt.figure(1)\n",
    "plt.plot(history_act1.history['val_acc'], 'r', label='val_accuracy')\n",
    "plt.plot(history_act1.history['acc'], 'y', label='accuracy')\n",
    "plt.plot(history_act1.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_act1.history['val_loss'] , 'g', label='val_loss')\n",
    "plt.title(\"activation = sigmoid\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history_act2.history['val_acc'], 'r',label='val_acc')\n",
    "plt.plot(history_act2.history['acc'],'y', label='accuracy')\n",
    "plt.plot(history_act2.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_act2.history['val_loss'], 'g',label='val_loss')\n",
    "plt.title(\"activation = tanh\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f8fff89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# # Adapting loss function\\nactivation = 'relu' # set activation back to relu\\n\\n# n_neurons = 10\\nn_neurons = 10\\nkeras_iteration1n = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_n1 = keras_iteration1n.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\\n\\n# n_neurons = 50\\nn_neurons = 50\\nkeras_iteration2n = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_n2 = keras_iteration2n.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\\n\\n# n_neurons = 100\\nn_neurons = 100\\nkeras_iteration3n = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\\nhistory_n3 = keras_iteration3n.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# # Adapting loss function\n",
    "activation = 'relu' # set activation back to relu\n",
    "\n",
    "# n_neurons = 10\n",
    "n_neurons = 10\n",
    "keras_iteration1n = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_n1 = keras_iteration1n.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\n",
    "\n",
    "# n_neurons = 50\n",
    "n_neurons = 50\n",
    "keras_iteration2n = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_n2 = keras_iteration2n.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "# n_neurons = 100\n",
    "n_neurons = 100\n",
    "keras_iteration3n = keras.wrappers.scikit_learn.KerasClassifier(neural_network)\n",
    "history_n3 = keras_iteration3n.fit(X_train_earth_pca, y_one_hot_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24b2a179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#PLOT RESULTS\\nplt.figure(1)\\nplt.plot(history_n1.history[\\'val_acc\\'], \\'r\\', label=\\'val_accuracy\\')\\nplt.plot(history_n1.history[\\'acc\\'], \\'y\\', label=\\'accuracy\\')\\nplt.plot(history_n1.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_n1.history[\\'val_loss\\'] , \\'g\\', label=\\'val_loss\\')\\nplt.title(\"10 neurons per hidden layer\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()\\n\\nplt.figure(2)\\nplt.plot(history_n2.history[\\'val_acc\\'], \\'r\\',label=\\'val_acc\\')\\nplt.plot(history_n2.history[\\'acc\\'],\\'y\\', label=\\'accuracy\\')\\nplt.plot(history_n2.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_n2.history[\\'val_loss\\'], \\'g\\',label=\\'val_loss\\')\\nplt.title(\"50 neurons per hidden layer\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()\\n\\n\\nplt.figure(3)\\nplt.plot(history_n3.history[\\'val_acc\\'], \\'r\\',label=\\'val_accuracy\\')\\nplt.plot(history_n3.history[\\'acc\\'], \\'y\\',label=\\'accuracy\\')\\nplt.plot(history_n3.history[\\'loss\\'], \\'b\\',label=\\'loss\\')\\nplt.plot(history_n3.history[\\'val_loss\\'] , \\'g\\',label=\\'val_loss\\')\\nplt.title(\"100 neurons per hidden layer\")\\nplt.xlabel(\\'epoch\\')\\nplt.ylabel(\\'loss/accuracy\\')\\nplt.legend()'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#PLOT RESULTS\n",
    "plt.figure(1)\n",
    "plt.plot(history_n1.history['val_acc'], 'r', label='val_accuracy')\n",
    "plt.plot(history_n1.history['acc'], 'y', label='accuracy')\n",
    "plt.plot(history_n1.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_n1.history['val_loss'] , 'g', label='val_loss')\n",
    "plt.title(\"10 neurons per hidden layer\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history_n2.history['val_acc'], 'r',label='val_acc')\n",
    "plt.plot(history_n2.history['acc'],'y', label='accuracy')\n",
    "plt.plot(history_n2.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_n2.history['val_loss'], 'g',label='val_loss')\n",
    "plt.title(\"50 neurons per hidden layer\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(history_n3.history['val_acc'], 'r',label='val_accuracy')\n",
    "plt.plot(history_n3.history['acc'], 'y',label='accuracy')\n",
    "plt.plot(history_n3.history['loss'], 'b',label='loss')\n",
    "plt.plot(history_n3.history['val_loss'] , 'g',label='val_loss')\n",
    "plt.title(\"100 neurons per hidden layer\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdc06e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Enabling Generalization (20 points)\n",
    "Now we are going to train and test a single model that is suitable for racing on all planets, i.e., a model that can generalize between planets and even to unseen planets, and that is robust to different colors of the background terrain. The idea is to take the final model you developed above as a starting point and to further develop it further for generalization.\n",
    "\n",
    "The simulator provides you access to Neptune. However, this is to be treated as the test set, i.e., you are only allowed to test your model on it as the very final step. I.e., do not tweak your model after running that environment, you would be overfitting to the test data. Performance on the Neptune environment will NOT influence your grade.\n",
    "\n",
    "1. How can the 3 provided datasets be used to train a model that can generalize, and even more importantly how can they be used to evaluate whether a model can generalize? (Hint: Lecture 2)\n",
    "2. Above you designed features for action classification, evaluate whether that feature is indeed suitable for generalization. If necessary adapt the feature extraction.\n",
    "3. Compare how well models trained just on the data from Earth and models trained on data of multiple planets generalize to unseen planets (using the approach from the first bullet, do *not* use Neptune for this comparison). Make sure that this is a fair comparison, e.g., in terms of the amount and quality of the data.\n",
    "4. Discuss at least 2 methods that can be employed to make your model perform better and be robust to the variations we have in this scenario (methods for any step are fine: data collection, data augmentation, pre-processing, model structure, training, etc.)\n",
    "5. Implement at least one of those methods.\n",
    "6. Evaluate the final model (similar to “Shortlist Promising Models” above) for generalization making use only of data from Earth, Mars, and Saturn.\n",
    "7. Test the final model on the Neptune environment and discuss its performance.\n",
    "8. Save the parameters of your best multi scenario model to your hard drive (use pickle for sklearn or built-in save/load for keras), you will need to be able to reload your model without training in the next step. Be sure to include the saved parameters in your zip file so we can evaluate your best model too, even without rerunning the notebook up to here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae221d",
   "metadata": {},
   "source": [
    "To check whether the model can generalize, we use the Earth datasets as training data and use the datasets from other planets as validation data. If the model succesfully classifies the actions on Mars and Saturn, the model is able to generalize since it has never seen these backgrounds. Moreover, in that scenario the model is likely to be succesfull on the third planet Neptune as well.\n",
    "\n",
    "The model obtained in the previous part is able to drive on planet Earth. However, if we run the simulator on another planet like Mars, the performance decreases drastically. The model does not generalize well enough yet. In order to be able to drive on every planet regardless of the background color, the features should be manipulated even more. \n",
    "\n",
    "The current feature extraction consist of gray-scaling the observation before feeding it to a Sobel filter. The light-green color of the Earth background is still light in constrast with the road if the Earth observation is transformed to grayscale. However, for other planets it is much more difficult to distinguish the background from the road, since the gray-scale converted background colors are darker and therefore resemble the road more. To completely get rid of the background color, an additional filter preserves only the road and whitenes all gray-values that exceed the gray-value of the road. \n",
    "\n",
    "Since the training data is equal for all planets now, there is no systematic difference between models that are trained just on Earth and models that are trained on multiple planets. The model sees no difference between samples from different planets so training on different planets does not have an impact on the performance of the model.\n",
    "\n",
    "There are various methods that can be employed to make the model perform better and be robuts to the variations. One of them is data augmentation. Data augmentation is a technique to artificially expand the size of the training set by creating modified versions of images in the dataset. This technique is used when the available dataset for training is too small to sufficiently train a model. This is not the case for this assignment, as there are 14000 available samples and adding more samples would only slow the model down instead of increasing accuracy. Another solution is pre-processing the data. In our model, we have extended pre-processing on the data, namely modifying the background color to white to simplify the model. Since the features in the model have been reduced using feature extraction, the model has modified to get a higher performance. The amount of features has been reduced by PCA so also the amount of neurons in the hidden layers have been decreased. What also has been found in the results of the model fine-tuning, is that less neurons in the hidden layer is more beneficial for the model.\n",
    "\n",
    "The accuracy and the f1-score of the model have decreased during the tweaking of our model. However, the performance of the racing car on all planets, including the validation data increased. The accuracy and the f1-score are good metrics to provide statistical information about the performance. In scenario however, it does not necessarily matter if the predicted action do not match the optimal actions. If an action 0 has been swapped with action 1, it does not influence the performance negatively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae785220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def feat_extract_final(X):\n",
    "    gray = rgb2gray(X)[:,20:80,20:80]\n",
    "    gray[gray>0.43] = 1\n",
    "    gray_test = gray[0]\n",
    "    obs_filter = np.zeros(gray.shape)\n",
    "    for i in range(len(X)):\n",
    "        obs_filter[i] = filters.sobel(gray[i])\n",
    "    obs_filter = obs_filter.reshape(obs_filter.shape[0], obs_filter.shape[1]*obs_filter.shape[2]) \n",
    "    plt.imshow(gray_test,cmap='gray')\n",
    "    return obs_filter\n",
    "\n",
    "def feature_vector_final(X):\n",
    "    gray = rgb2gray(X)[20:80,20:80]\n",
    "    gray[gray>0.43] = 1\n",
    "    gray_test = gray[0]\n",
    "    obs_filter = filters.sobel(gray)\n",
    "    obs_filter = obs_filter.reshape(1, obs_filter.shape[0]*obs_filter.shape[1]) \n",
    "    return obs_filter\n",
    "\n",
    "feat_extract_final(observations[10001:10003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fee30157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500 1700 1300 1180]\n",
      "Train on 5344 samples, validate on 1336 samples\n",
      "Epoch 1/50\n",
      "5344/5344 [==============================] - 1s 167us/sample - loss: 1.1795 - acc: 0.5818 - val_loss: 1.4127 - val_acc: 0.2822\n",
      "Epoch 2/50\n",
      "5344/5344 [==============================] - 1s 138us/sample - loss: 1.0712 - acc: 0.6067 - val_loss: 1.3615 - val_acc: 0.4731\n",
      "Epoch 3/50\n",
      "5344/5344 [==============================] - 1s 127us/sample - loss: 1.0521 - acc: 0.6201 - val_loss: 1.1696 - val_acc: 0.4895\n",
      "Epoch 4/50\n",
      "5344/5344 [==============================] - 1s 129us/sample - loss: 1.0427 - acc: 0.6158 - val_loss: 1.2211 - val_acc: 0.5254\n",
      "Epoch 5/50\n",
      "5344/5344 [==============================] - 1s 131us/sample - loss: 1.0276 - acc: 0.6158 - val_loss: 1.2049 - val_acc: 0.4731\n",
      "Epoch 6/50\n",
      "5344/5344 [==============================] - 1s 122us/sample - loss: 1.0273 - acc: 0.6304 - val_loss: 1.4108 - val_acc: 0.3540\n",
      "Epoch 7/50\n",
      "5344/5344 [==============================] - 1s 132us/sample - loss: 1.0392 - acc: 0.6196 - val_loss: 1.2666 - val_acc: 0.4603\n",
      "Epoch 8/50\n",
      "5344/5344 [==============================] - ETA: 0s - loss: 1.0390 - acc: 0.622 - 1s 131us/sample - loss: 1.0370 - acc: 0.6229 - val_loss: 1.3218 - val_acc: 0.4364\n",
      "Epoch 9/50\n",
      "5344/5344 [==============================] - 1s 129us/sample - loss: 1.0293 - acc: 0.6325 - val_loss: 1.2638 - val_acc: 0.4880\n",
      "Epoch 10/50\n",
      "5344/5344 [==============================] - 1s 126us/sample - loss: 1.0234 - acc: 0.6310 - val_loss: 1.2990 - val_acc: 0.4835\n",
      "Epoch 11/50\n",
      "5344/5344 [==============================] - 1s 130us/sample - loss: 1.0280 - acc: 0.6332 - val_loss: 1.4043 - val_acc: 0.3533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26548c1ff88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We only used data from earth, now we will use data from Mars an Saturn\n",
    "samples = observations[0:10000]\n",
    "sample_actions = actions[0:10000]\n",
    "# samples_val = observations[10000:14000]\n",
    "# sample_actions_val = actions[10000:14000]\n",
    "\n",
    "## Distribute actions more evenly\n",
    "samples_distributed, sample_actions_distributed = distribute(samples, sample_actions, 0, 800, 1200, 0, 0, 2500)\n",
    "# samples_val_distributed, sample_val_actions_distributed = distribute(samples_val, sample_actions_val, 0, 250, 450, 0, 0, 1000)\n",
    "print(np.bincount(sample_actions_distributed))\n",
    "# print(np.bincount(sample_val_actions_distributed))\n",
    "\n",
    "# Extract features of the samples\n",
    "X_final_train, y_final_train = feat_extract(samples_distributed), sample_actions_distributed\n",
    "# X_final_val, y_final_val = feat_extract(samples_val_distributed), sample_val_actions_distributed\n",
    "pca = PCA(n_components = 0.95)\n",
    "\n",
    "# Prepare data for neural network\n",
    "X_final_train_pca = pca.fit_transform(X_final_train)\n",
    "# X_final_val_pca = pca.transform(X_final_val)\n",
    "y_one_hot_final_train = one_hot_encoding(y_final_train)\n",
    "# y_one_hot_final_val = one_hot_encoding(y_final_val)\n",
    "\n",
    "# # Neural network settings\n",
    "learning_rate = 0.01\n",
    "n_neurons = 10\n",
    "n_hidden = 2\n",
    "epochs = 50\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
    "nn_final = neural_network()\n",
    "nn_final.fit(X_final_train_pca, y_one_hot_final_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,callbacks=[early_stopping])\n",
    "\n",
    "# y_val_pred = nn_final.predict(y_final_val)\n",
    "# y_final_pred = np.argmax(y_val_pred, axis=0)\n",
    "\n",
    "# print(y_val_pred)\n",
    "# print(y_val_pred.shape)\n",
    "# print(y_final_val)\n",
    "# print(y_final_val.shape)\n",
    "\n",
    "# Score metrics\n",
    "# accuracy = sklearn.metrics.accuracy_score(y_final_val, y_val_pred) \n",
    "# f1score = f1_score(y_final_val, y_val_pred, average='macro')\n",
    "# print(f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578f514",
   "metadata": {},
   "source": [
    "### Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8c24d95",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-89e9f2389d40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnn_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'final_neural_network_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# nn_final.save(r'C:\\Users\\jobmu\\OneDrive\\Documenten\\final_neural_network_model.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    144\u001b[0m       h5py is not None and (\n\u001b[0;32m    145\u001b[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m    212\u001b[0m                                                custom_objects=custom_objects)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# nn_final = load_model('final_neural_network_model.h5')\n",
    "nn_final.save(r'C:\\Users\\jobmu\\OneDrive\\Documenten\\final_neural_network_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b5093",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Present Your Solution (5 points)\n",
    "1. Summarize your main decisions and insights\n",
    "2. Create a stand-alone demo. I.e., a block of cells that can be run on its own. For that you will need to load your pre-trained best model you saved in the previous section and run it on a Neptune track.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a583d",
   "metadata": {},
   "source": [
    "### Conclusion and insights\n",
    "\n",
    "For the final model we decided to train a neural network for a good performance of the racing car. The performance at the beginning was poor so we started to optimize the neural network. After a lot of iterations we figured out that even though the accuracy did not improve, had a better performance on the track. Also the f1 score did not always indicate a good performance of the track. The methodology of filtering out the background color which indicates the planet did not work out as we expected. Even though the racing car performs well on earth, mars and saturn, the performance on neptune is very poor. Although the performance of our model is not the best, the assignment gave us insights of how to and how not to build a model for such tasks.\n",
    "There are a lot of insights we had this practicum. We spent multiple days from 9am to 12pm to perform iterations trying to improve the metrics. After some time we found out that the f1 score an accuracy did not immediately improve the performance of the racing car. We figured out that one of the most important steps of building a model is the preprocessing of the data. \n",
    "\n",
    "The performance on earth, mars and saturn were good. However, the performance on neptune was very poor. This means we probably overfitted the model on the data. What would have been better was, besides training the model on the earth data, to validate the model on only one unknown planet and perform the test on the last unknown planet. In this way, the f1 score and the accuracy tells much more about the performance of the model which could result in a better performance on neptune. Since we ran out of time, we could not implement this insight on time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3afe5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def f_policy_neural_network(observation):\n",
    "    observation = feature_vector_final(observation)\n",
    "    observation = pca.transform(observation)\n",
    "    action = np.argmax(nn_final.predict(observation))\n",
    "    \n",
    "    print(f'Received observation: {observation.shape} numpy array of type {observation.dtype}, returning action {action}')\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6d6e29f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation for 500 iterations.\n",
      "*** Press ESC key in popup window to stop the simulation! ***\n",
      "\n",
      "Track generation: 1216..1525 -> 309-tiles track\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobmu\\Miniconda3\\envs\\tf2\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 1\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 2\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 3\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "Received observation: (1, 759) numpy array of type float64, returning action 0\n",
      "total reward after 456 iterations: 344.01038961038745\n",
      "average reward: 0.7544087491455865\n"
     ]
    }
   ],
   "source": [
    "rs = run_simulation(f_policy_neural_network, render=1, planet_id=2, track_id=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46aadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
